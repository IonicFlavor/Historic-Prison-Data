CN: 1) Visualization description: I visualized word frequencies in moral instructor’s notes of inmates and created a “Corpus A” with the characteristics Male, Illiterate, All Sobriety Categories, and All Admission Books and “Corpus B” with the characteristics Male, Reads and Writes, All Sobriety Categories, and All Admission Books. I wanted to isolate the literacy categorization and how it influenced the most common words in moral instructor’s notes. In the Comparative Frequencies plot, words such as “affirms”, “god”, “dead” and “parents” appear with near equal frequency in each plot. However, words associated with literate prisoners are generally more positive (“real”, “baptist”, “pious”, “business”, “child”, etc.) while words associated with illiterate prisoners are more negative (“enmity”, “stupid”, “ignorant”, etc.).
2) Relationship between visualization and repo: The word cloud processes all three admissions books in the repo (A, B, and D). It appears to look at the ColumnNote column and pulls out relevant words to determine whether an inmate can read, write, both, or neither. There is also an option for "Reads other language". The other levers that can be changed are "Admission Book" (A, B, D); "Sobriety" (Sober, Drinks, Drinks a Little, Drinks Often); and "Gender" (Female, Male, All). The visualization selects specific inmate entries based on the specifications and then plots commonly-repeated words from moral instructors' notes. A lot of these words, surprisingly, appear to not be articles such as "the", but more unique words such as "baptist" or "real".
3) Dara errors/limitations: The classification of "can read and write" (calling literate for ease) vs illiterate may be a cause for some confusion in the data since it appears it is based off the column called ColumnNote, which doesn’t clearly separate people who are slightly familiar with reading and writing versus people who are very fluent in reading and writing. Also, while some of these words in the Comparative Frequencies may initially appear positive, they don’t capture context (for example, one of the literate inmates was described as “professing to be God”, which is not positive). This means the connotations of these words can't necessarily be assumed. 
4) Additional visualizations + necessary data: It would be interesting to conduct a sentiment analysis on these words and see how they relate on performance assessment of prisoners (i.e. extending sentence based on bad conduct and reducing sentence based on good conduct) and looking at whether there is correlation with these description. For example, the number of sentence extensions / reductions could be plotted in relation to the positivity/negativity of the words moral instructors used to describe inmates. However, this would require additional data/information on the connotation surrounding these common words used to describe the inmates (i.e., the God example above); this might be difficult to conduct textual analysis on but there could be the incorporation of machine learning or human researchers marking whether or not certain words actually have positive or negative connotations. 