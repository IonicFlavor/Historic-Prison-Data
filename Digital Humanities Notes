
JS - The app 3 data visualization compares different groups, such as gender and country of origin, with the length of sentence they face. The admissions book data has a section with how long the sentence of a person is, which is where they got their data. The data only shows at a range of sentences for months. You can only look at disparities in sentence between races by a range of months. You can't see the difference of races and compare them with a 1 month sentence and a 12 month sentence at the same time. It would be interesting to see how multiple factors, such as age and number of convictions, relate to the sentence length of an inmate. This data is already available in the admission books.

JS- The app 1 data visualization compares different groups, such as males and females, literate and not literate, etc, with their word frequencies in the Moral Instructor's notes. The data uses the Moral Instructors notes in the repo, and counts the times it was used by a certain group. With so many words, some words are left out and not defined, which can be very limiting. One minor revision, could be to color code the words based on if they are "negative" or "positive" or "neutral". All of these terms are subjective as not everyone may agree that a word is positive and such, but it would be interesting. This would require someone to judge words based on if they think the word is positive, negative, or neutral. It would also be interesting to compare the word usage as it compares to moral instructors. Unfortunately, the data in the repo doesn't have the author of the instructor notes, so this would be rather hard to do. But it would allow us to see if one instructor may have been known to use a particular word. We may want to remove data like this to get a better correlation. It would also be interesting to know how strong the data is correlated. I wished the creators added a correlation coefficient. The red line they have through the data is a nice touch. 